# 很大声周刊-vol.150
![Title_WeChat_150](https://github.com/user-attachments/assets/eee6d8f4-ec6a-4b37-877a-e1bfa654ddbc)

# 在离线渲染中实现节奏控制

稍微有点绕，先说实时渲染的节奏控制，这个很好理解，节奏和画面渲染都是实时运行的，所以在时间上是完全同步的，节奏发出的信号会同步体现在渲染画面中。

离线渲染就不是这么回事了，离线渲染的特性就是通过更长的渲染时间换取更高质量的渲染结果，这种情况下节奏发出的信号不能同步反应在渲染结果中。

其实也很简单，最常用的关键帧就是在解决这个问题，可是关键帧实现节奏控制很麻烦、调试成本也很高，我想能不能通过更自动化方式完成这件事。

Houdini 在这方面做的很好，除了用已有的模块外，还可以直接在节点中嵌入代码，更准确地实现自己的需求，这是最近的一项测试。

![693_StringArray_Index-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/2462c2ad-88a1-4661-8b4e-ae1dbac58ac2)

![image](https://github.com/user-attachments/assets/92e8c5fa-1252-40fc-8cf8-2384ad07d772)

``` C++
string strs[] = {"123", "abc", "!@#"};

if (@Frame % 10 == 1) @index ++;

@index = @index % len(strs); // 如果超出长度则循环回第一个元素
s@str = strs[i@index]; // 选择当前索引的字符串
```

类似需求实现起来很方便，所以这个尝试也就用 Houdini 来实现了。

关键帧和节奏都是时间概念，既然都是时间概念，那应该就能互相转换，就像分、秒，米、厘米一样能互相转换。这东西有点复杂，我能做的只有尽量把问题描述清楚，交给 ChatGTP，经过几轮调试果然得到了不错的答案，原理就是各种转换，现在只要写好在第几个音符上触发，程序会自动转换成关键帧动画，调试只需要更改音符就好。

它需要你对代码、节奏有一定的了解，没啥硬性要求，代码部分的底线是能看懂它在干什么，节奏部分的底线是知道如何描述需求。比如，120 BPM 1 / 32（每分钟 120 拍的速度，每拍 32 个音符），我需要在第 1、9、17、25 个音符触发等等。

如果你也遇到类似需求，或者就想做一些奇怪的尝试，希望这对你有帮助，下期再见。